{"paragraphs":[{"title":"1. List all content in current directory","text":"ls","user":"yava","dateUpdated":"2019-12-18T09:59:08-0500","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1576681148277_-233797705","id":"20191216-080314_536904622","dateCreated":"2019-12-18T09:59:08-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:3053"},{"title":"2. List content of dataset directory","text":"ls dataset","user":"yava","dateUpdated":"2019-12-18T09:59:08-0500","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1576681148278_-1900361319","id":"20191216-080317_1279071974","dateCreated":"2019-12-18T09:59:08-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3054"},{"title":"3. Create datset directory on HDFS","text":"hdfs dfs -mkdir dataset","user":"yava","dateUpdated":"2019-12-18T09:59:47-0500","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1576681148279_1842183629","id":"20191216-081404_338722865","dateCreated":"2019-12-18T09:59:08-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3055"},{"text":"hdfs dfs -ls dataset","user":"yava","dateUpdated":"2019-12-18T09:59:08-0500","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"editorHide":false,"title":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1576681148279_1251507816","id":"20191216-080325_2016982904","dateCreated":"2019-12-18T09:59:08-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3056"},{"title":"4. Upload dataset into HDFS","text":"hdfs dfs -put dataset/wordcount_sample.dat dataset","user":"yava","dateUpdated":"2019-12-18T10:01:29-0500","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1576681148280_540626859","id":"20191216-080334_158836657","dateCreated":"2019-12-18T09:59:08-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3057"},{"text":"hdfs dfs -ls dataset","user":"yava","dateUpdated":"2019-12-18T09:59:08-0500","config":{"tableHide":false,"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/sh","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1576681148280_410994056","id":"20191216-080458_1146278445","dateCreated":"2019-12-18T09:59:08-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3058"},{"title":"5. View dataset on HDFS","text":"hdfs dfs -cat dataset/wordcount_sample.dat","user":"yava","dateUpdated":"2019-12-18T10:01:22-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"editorMode":"ace/mode/sh","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1576681234666_-656503063","id":"20191218-100034_938706920","dateCreated":"2019-12-18T10:00:34-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3059"},{"user":"yava","dateUpdated":"2019-12-18T09:59:08-0500","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionSupport":false},"editorMode":"ace/mode/sh"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1576681148284_-37550460","id":"20191216-082121_1376541740","dateCreated":"2019-12-18T09:59:08-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:3060"}],"name":"Big Data Analytics Quick Start/LABS 02: Upload Data Into HDFS","id":"2EXWK8ZAW","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"hive:yava:":[],"sh:yava:":[],"spark:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}